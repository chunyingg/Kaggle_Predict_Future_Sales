{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=3, minor=5, micro=6, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(23333)\n",
    "np.random.seed(233333)\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model : Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data.pkl')\n",
    "# do not use ID features\n",
    "data = data[[\n",
    "    'date_block_num',\n",
    "    #'shop_id',\n",
    "    #'item_id',\n",
    "    'item_cnt_month',\n",
    "    #'city_code',\n",
    "    #'item_category_id',\n",
    "    #'type_code','subtype_code',\n",
    "    'item_cnt_month_lag_1','item_cnt_month_lag_2','item_cnt_month_lag_3','item_cnt_month_lag_6','item_cnt_month_lag_12',\n",
    "    'item_avg_sale_last_6', 'item_std_sale_last_6',\n",
    "    'item_avg_sale_last_12', 'item_std_sale_last_12',\n",
    "    'shop_avg_sale_last_6', 'shop_std_sale_last_6',\n",
    "    'shop_avg_sale_last_12', 'shop_std_sale_last_12',\n",
    "    'category_avg_sale_last_12', 'category_std_sale_last_12',\n",
    "    'city_avg_sale_last_12', 'city_std_sale_last_12',\n",
    "    'type_avg_sale_last_12', 'type_std_sale_last_12',\n",
    "    'subtype_avg_sale_last_12', 'subtype_std_sale_last_12',\n",
    "    'date_avg_item_cnt_lag_1',\n",
    "    'date_item_avg_item_cnt_lag_1','date_item_avg_item_cnt_lag_2','date_item_avg_item_cnt_lag_3','date_item_avg_item_cnt_lag_6','date_item_avg_item_cnt_lag_12',\n",
    "    'date_shop_avg_item_cnt_lag_1','date_shop_avg_item_cnt_lag_2','date_shop_avg_item_cnt_lag_3','date_shop_avg_item_cnt_lag_6','date_shop_avg_item_cnt_lag_12',\n",
    "    'date_cat_avg_item_cnt_lag_1',\n",
    "    'date_shop_cat_avg_item_cnt_lag_1',\n",
    "    'date_city_avg_item_cnt_lag_1',\n",
    "    'date_item_city_avg_item_cnt_lag_1',\n",
    "    'delta_price_lag',\n",
    "    'month','year',\n",
    "    'item_shop_last_sale','item_last_sale',\n",
    "    'item_shop_first_sale','item_first_sale',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練集、校正集 產生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_train = data[data.date_block_num < 33]['item_cnt_month']\n",
    "X_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n",
    "Y_valid = data[data.date_block_num == 33]['item_cnt_month']\n",
    "X_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1)\n",
    "\n",
    "del data\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立NN模型，調整參數\n",
    "## try1\n",
    "\n",
    "* 建立四層layer(神經元個數分別為128,64,32,1)\n",
    "* batch size = 1000\n",
    "* epochs = 20\n",
    "* learning rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6186922 samples, validate on 238172 samples\n",
      "Epoch 1/20\n",
      "6186922/6186922 [==============================] - 37s 6us/step - loss: 0.8845 - mean_squared_error: 0.8184 - val_loss: 0.9694 - val_mean_squared_error: 0.9056\n",
      "Epoch 2/20\n",
      "6186922/6186922 [==============================] - 35s 6us/step - loss: 0.8677 - mean_squared_error: 0.8009 - val_loss: 0.9720 - val_mean_squared_error: 0.9020\n",
      "Epoch 3/20\n",
      "6186922/6186922 [==============================] - 36s 6us/step - loss: 0.8657 - mean_squared_error: 0.7978 - val_loss: 0.9846 - val_mean_squared_error: 0.9156\n",
      "Epoch 4/20\n",
      "6186922/6186922 [==============================] - 38s 6us/step - loss: 0.8651 - mean_squared_error: 0.7968 - val_loss: 0.9611 - val_mean_squared_error: 0.8928\n",
      "Epoch 5/20\n",
      "6186922/6186922 [==============================] - 36s 6us/step - loss: 0.8644 - mean_squared_error: 0.7959 - val_loss: 0.9618 - val_mean_squared_error: 0.8927\n",
      "Epoch 6/20\n",
      "6186922/6186922 [==============================] - 37s 6us/step - loss: 0.8641 - mean_squared_error: 0.7957 - val_loss: 0.9560 - val_mean_squared_error: 0.8884\n",
      "Epoch 7/20\n",
      "6186922/6186922 [==============================] - 33s 5us/step - loss: 0.8640 - mean_squared_error: 0.7954 - val_loss: 0.9688 - val_mean_squared_error: 0.8992\n",
      "Epoch 8/20\n",
      "6186922/6186922 [==============================] - 37s 6us/step - loss: 0.8638 - mean_squared_error: 0.7953 - val_loss: 0.9623 - val_mean_squared_error: 0.8929\n",
      "Epoch 9/20\n",
      "6186922/6186922 [==============================] - 37s 6us/step - loss: 0.8638 - mean_squared_error: 0.7954 - val_loss: 0.9661 - val_mean_squared_error: 0.8978\n",
      "Epoch 10/20\n",
      "6186922/6186922 [==============================] - 35s 6us/step - loss: 0.8638 - mean_squared_error: 0.7955 - val_loss: 0.9548 - val_mean_squared_error: 0.8854\n",
      "Epoch 11/20\n",
      "6186922/6186922 [==============================] - 37s 6us/step - loss: 0.8637 - mean_squared_error: 0.7949 - val_loss: 0.9624 - val_mean_squared_error: 0.8945\n",
      "Epoch 12/20\n",
      "6186922/6186922 [==============================] - 35s 6us/step - loss: 0.8637 - mean_squared_error: 0.7954 - val_loss: 0.9631 - val_mean_squared_error: 0.8929\n",
      "Epoch 13/20\n",
      "6186922/6186922 [==============================] - 38s 6us/step - loss: 0.8636 - mean_squared_error: 0.7951 - val_loss: 0.9588 - val_mean_squared_error: 0.8901\n",
      "Epoch 14/20\n",
      "6186922/6186922 [==============================] - 40s 6us/step - loss: 0.8634 - mean_squared_error: 0.7948 - val_loss: 0.9722 - val_mean_squared_error: 0.9020\n",
      "Epoch 15/20\n",
      "6186922/6186922 [==============================] - 36s 6us/step - loss: 0.8634 - mean_squared_error: 0.7947 - val_loss: 0.9702 - val_mean_squared_error: 0.9021\n",
      "Epoch 16/20\n",
      "6186922/6186922 [==============================] - 37s 6us/step - loss: 0.8634 - mean_squared_error: 0.7950 - val_loss: 0.9637 - val_mean_squared_error: 0.8953\n",
      "Epoch 17/20\n",
      "6186922/6186922 [==============================] - 36s 6us/step - loss: 0.8633 - mean_squared_error: 0.7945 - val_loss: 0.9533 - val_mean_squared_error: 0.8871\n",
      "Epoch 18/20\n",
      "6186922/6186922 [==============================] - 38s 6us/step - loss: 0.8636 - mean_squared_error: 0.7954 - val_loss: 0.9562 - val_mean_squared_error: 0.8875\n",
      "Epoch 19/20\n",
      "6186922/6186922 [==============================] - 36s 6us/step - loss: 0.8634 - mean_squared_error: 0.7948 - val_loss: 0.9531 - val_mean_squared_error: 0.8866\n",
      "Epoch 20/20\n",
      "6186922/6186922 [==============================] - 35s 6us/step - loss: 0.8634 - mean_squared_error: 0.7948 - val_loss: 0.9684 - val_mean_squared_error: 0.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122625828>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "def Sales_prediction_model(input_shape):\n",
    "    in_layer = Input(input_shape)\n",
    "    x = Dense(128,kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(in_layer)\n",
    "    x = Dense(64, kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(x)\n",
    "    x = Dense(32, kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(x)\n",
    "    x = Dense(1, kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(x)\n",
    "    \n",
    "    model = Model(inputs = in_layer, outputs = x, name='Sales_prediction_model')\n",
    "    return model\n",
    "\n",
    "# NN cannot take missing values, fill NaN with 0.\n",
    "X_train.fillna(0,inplace=True)\n",
    "X_valid.fillna(0,inplace=True)\n",
    "X_test.fillna(0,inplace=True)\n",
    "\n",
    "# We do no feature scaling here. \n",
    "# Some features like 'item_avg_sale_last_6' are already scaled in feature engineering part.\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n",
    "model = Sales_prediction_model(input_shape)\n",
    "model.compile(optimizer = Adam(lr=0.0005) , loss = [\"mse\"], metrics=['mse'])\n",
    "model.fit(X_train, Y_train, validation_data = (X_valid, Y_valid), batch_size = 1000, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try2\n",
    "\n",
    "* 建立三層layer(神經元個數分別為16,8,1)\n",
    "* batch size = 10000\n",
    "* epochs = 5\n",
    "* learning rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6186922 samples, validate on 238172 samples\n",
      "Epoch 1/5\n",
      "6186922/6186922 [==============================] - 18s 3us/step - loss: 0.9942 - mean_squared_error: 0.9511 - val_loss: 0.9583 - val_mean_squared_error: 0.9089\n",
      "Epoch 2/5\n",
      "6186922/6186922 [==============================] - 14s 2us/step - loss: 0.8583 - mean_squared_error: 0.8121 - val_loss: 0.9478 - val_mean_squared_error: 0.9032\n",
      "Epoch 3/5\n",
      "6186922/6186922 [==============================] - 15s 2us/step - loss: 0.8505 - mean_squared_error: 0.8067 - val_loss: 0.9501 - val_mean_squared_error: 0.9071\n",
      "Epoch 4/5\n",
      "6186922/6186922 [==============================] - 16s 3us/step - loss: 0.8472 - mean_squared_error: 0.8038 - val_loss: 0.9413 - val_mean_squared_error: 0.8981\n",
      "Epoch 5/5\n",
      "6186922/6186922 [==============================] - 17s 3us/step - loss: 0.8455 - mean_squared_error: 0.8016 - val_loss: 0.9424 - val_mean_squared_error: 0.8977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f8eb5f8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "def Sales_prediction_model(input_shape):\n",
    "    in_layer = Input(input_shape)\n",
    "    x = Dense(16,kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(in_layer)\n",
    "    x = Dense(8, kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(x)\n",
    "    x = Dense(1, kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(x)\n",
    "    \n",
    "    model = Model(inputs = in_layer, outputs = x, name='Sales_prediction_model')\n",
    "    return model\n",
    "\n",
    "# NN cannot take missing values, fill NaN with 0.\n",
    "X_train.fillna(0,inplace=True)\n",
    "X_valid.fillna(0,inplace=True)\n",
    "X_test.fillna(0,inplace=True)\n",
    "\n",
    "# We do no feature scaling here. \n",
    "# Some features like 'item_avg_sale_last_6' are already scaled in feature engineering part.\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n",
    "model = Sales_prediction_model(input_shape)\n",
    "model.compile(optimizer = Adam(lr=0.0005) , loss = [\"mse\"], metrics=['mse'])\n",
    "model.fit(X_train, Y_train, validation_data = (X_valid, Y_valid), batch_size = 10000, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try3\n",
    "\n",
    "* 建立三層layer(神經元個數分別為8,2,1)\n",
    "* batch size = 10000\n",
    "* epochs = 5\n",
    "* learning rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6186922 samples, validate on 238172 samples\n",
      "Epoch 1/5\n",
      "6186922/6186922 [==============================] - 16s 3us/step - loss: 1.0759 - mean_squared_error: 1.0392 - val_loss: 0.9707 - val_mean_squared_error: 0.9209\n",
      "Epoch 2/5\n",
      "6186922/6186922 [==============================] - 16s 3us/step - loss: 0.8634 - mean_squared_error: 0.8177 - val_loss: 0.9593 - val_mean_squared_error: 0.9159\n",
      "Epoch 3/5\n",
      "6186922/6186922 [==============================] - 17s 3us/step - loss: 0.8543 - mean_squared_error: 0.8114 - val_loss: 0.9450 - val_mean_squared_error: 0.9025\n",
      "Epoch 4/5\n",
      "6186922/6186922 [==============================] - 16s 3us/step - loss: 0.8503 - mean_squared_error: 0.8079 - val_loss: 0.9427 - val_mean_squared_error: 0.9000\n",
      "Epoch 5/5\n",
      "6186922/6186922 [==============================] - 16s 3us/step - loss: 0.8482 - mean_squared_error: 0.8058 - val_loss: 0.9449 - val_mean_squared_error: 0.9022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ebaf438>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "def Sales_prediction_model(input_shape):\n",
    "    in_layer = Input(input_shape)\n",
    "    x = Dense(8,kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(in_layer)\n",
    "    x = Dense(2, kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(x)\n",
    "    x = Dense(1, kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(x)\n",
    "    \n",
    "    model = Model(inputs = in_layer, outputs = x, name='Sales_prediction_model')\n",
    "    return model\n",
    "\n",
    "# NN cannot take missing values, fill NaN with 0.\n",
    "X_train.fillna(0,inplace=True)\n",
    "X_valid.fillna(0,inplace=True)\n",
    "X_test.fillna(0,inplace=True)\n",
    "\n",
    "# We do no feature scaling here. \n",
    "# Some features like 'item_avg_sale_last_6' are already scaled in feature engineering part.\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n",
    "model = Sales_prediction_model(input_shape)\n",
    "model.compile(optimizer = Adam(lr=0.0005) , loss = [\"mse\"], metrics=['mse'])\n",
    "model.fit(X_train, Y_train, validation_data = (X_valid, Y_valid), batch_size = 10000, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try4\n",
    "\n",
    "* 建立三層layer(神經元個數分別為8,2,1)\n",
    "* batch size = 10000\n",
    "* epochs = 10\n",
    "* learning rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6186922 samples, validate on 238172 samples\n",
      "Epoch 1/10\n",
      "6186922/6186922 [==============================] - 18s 3us/step - loss: 1.0849 - mean_squared_error: 1.0424 - val_loss: 0.9824 - val_mean_squared_error: 0.9218\n",
      "Epoch 2/10\n",
      "6186922/6186922 [==============================] - 17s 3us/step - loss: 0.8744 - mean_squared_error: 0.8200 - val_loss: 0.9584 - val_mean_squared_error: 0.9073\n",
      "Epoch 3/10\n",
      "6186922/6186922 [==============================] - 17s 3us/step - loss: 0.8628 - mean_squared_error: 0.8126 - val_loss: 0.9566 - val_mean_squared_error: 0.9066\n",
      "Epoch 4/10\n",
      "6186922/6186922 [==============================] - 13s 2us/step - loss: 0.8582 - mean_squared_error: 0.8086 - val_loss: 0.9506 - val_mean_squared_error: 0.9011\n",
      "Epoch 5/10\n",
      "6186922/6186922 [==============================] - 17s 3us/step - loss: 0.8556 - mean_squared_error: 0.8064 - val_loss: 0.9490 - val_mean_squared_error: 0.8997\n",
      "Epoch 6/10\n",
      "6186922/6186922 [==============================] - 17s 3us/step - loss: 0.8535 - mean_squared_error: 0.8045 - val_loss: 0.9523 - val_mean_squared_error: 0.9031\n",
      "Epoch 7/10\n",
      "6186922/6186922 [==============================] - 16s 3us/step - loss: 0.8521 - mean_squared_error: 0.8032 - val_loss: 0.9467 - val_mean_squared_error: 0.8982\n",
      "Epoch 8/10\n",
      "6186922/6186922 [==============================] - 19s 3us/step - loss: 0.8510 - mean_squared_error: 0.8027 - val_loss: 0.9448 - val_mean_squared_error: 0.8967\n",
      "Epoch 9/10\n",
      "6186922/6186922 [==============================] - 14s 2us/step - loss: 0.8502 - mean_squared_error: 0.8023 - val_loss: 0.9475 - val_mean_squared_error: 0.8996\n",
      "Epoch 10/10\n",
      "6186922/6186922 [==============================] - 12s 2us/step - loss: 0.8493 - mean_squared_error: 0.8018 - val_loss: 0.9432 - val_mean_squared_error: 0.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f0253c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "def Sales_prediction_model(input_shape):\n",
    "    in_layer = Input(input_shape)\n",
    "    x = Dense(8,kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(in_layer)\n",
    "    x = Dense(2, kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(x)\n",
    "    x = Dense(1, kernel_initializer='RandomUniform', kernel_regularizer=l2(0.02), activation = \"relu\")(x)\n",
    "    \n",
    "    model = Model(inputs = in_layer, outputs = x, name='Sales_prediction_model')\n",
    "    return model\n",
    "\n",
    "# NN cannot take missing values, fill NaN with 0.\n",
    "X_train.fillna(0,inplace=True)\n",
    "X_valid.fillna(0,inplace=True)\n",
    "X_test.fillna(0,inplace=True)\n",
    "\n",
    "# We do no feature scaling here. \n",
    "# Some features like 'item_avg_sale_last_6' are already scaled in feature engineering part.\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n",
    "model = Sales_prediction_model(input_shape)\n",
    "model.compile(optimizer = Adam(lr=0.0005) , loss = [\"mse\"], metrics=['mse'])\n",
    "model.fit(X_train, Y_train, validation_data = (X_valid, Y_valid), batch_size = 10000, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結論：try2的結果是最好的 LB score為0.91多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
